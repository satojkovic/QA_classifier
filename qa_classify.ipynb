{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import os\n",
    "import subprocess\n",
    "import urllib\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You already downloaded: qa_Appliances.json.gz\n",
      "You already downloaded: GoogleNews-vectors-negative300.bin\n"
     ]
    }
   ],
   "source": [
    "# Downloading datasets and pre-trained embeddings\n",
    "dataset_name = 'qa_Appliances.json.gz'\n",
    "url_dataset = 'http://jmcauley.ucsd.edu/data/amazon/qa'\n",
    "if not os.path.exists(dataset_name):\n",
    "    subprocess.run(['wget',  urllib.parse.urljoin(url_dataset, dataset_name)])\n",
    "    subprocess.run(['gzip -d', dataset_name])\n",
    "else:\n",
    "    print('You already downloaded:', dataset_name)\n",
    "\n",
    "embedding_name = 'GoogleNews-vectors-negative300.bin'\n",
    "url_embed = 'https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing'\n",
    "if not os.path.exists(embedding_name):\n",
    "    subprocess.run(['wget', url_embed])\n",
    "else:\n",
    "    print('You already downloaded:', embedding_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load pre-trained word2vec model\n",
    "googlenews_w2v = gensim.models.KeyedVectors.load_word2vec_format(embedding_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9011\n",
      "9011\n"
     ]
    }
   ],
   "source": [
    "# load datasets\n",
    "# you cannot use json.load because this json file is invalid format...(using single quote)\n",
    "\n",
    "dataset = dataset_name[:-3]  # remove .gz\n",
    "\n",
    "questions = []\n",
    "answers = []\n",
    "with open(dataset, 'r') as f:\n",
    "    for line in f:\n",
    "        js = ast.literal_eval(line)\n",
    "        questions.append(js['question'])\n",
    "        answers.append(js['answer'])\n",
    "print(len(questions))\n",
    "print(len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 13516 Test: 4506\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into train and test set\n",
    "qa_texts = np.array(questions + answers)\n",
    "qa_labels = np.zeros(len(qa_texts), dtype=np.int)\n",
    "qa_labels[len(questions):] = 1  # question: 0, answer: 1\n",
    "\n",
    "qa_idx = np.random.permutation(len(qa_texts))\n",
    "qa_texts = qa_texts[qa_idx]\n",
    "qa_labels = qa_labels[qa_idx]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(qa_texts, qa_labels)\n",
    "print('Train:', len(X_train), 'Test:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple word embedding feature by averaging word vectors for all words in a text\n",
    "# ref: http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/#comment-3233012354\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec, dim):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = dim\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('word2vec', <__main__.MeanEmbeddingVectorizer object at 0x24c115c18>), ('randomforest', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=200, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a model\n",
    "rf_amazon_qa = Pipeline([\n",
    "    ('word2vec', MeanEmbeddingVectorizer(googlenews_w2v, googlenews_w2v.vector_size)), \n",
    "    ('randomforest', RandomForestClassifier(n_estimators=200))])\n",
    "rf_amazon_qa.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.82      0.79      2280\n",
      "          1       0.80      0.74      0.77      2226\n",
      "\n",
      "avg / total       0.78      0.78      0.78      4506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_pred = rf_amazon_qa.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
